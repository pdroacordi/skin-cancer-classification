#!/usr/bin/env python3
"""
Script final para executar an√°lise completa dos resultados.
Resolve os problemas de m√©tricas zeradas e gera o gr√°fico comparativo solicitado.

Uso:
    python run_analysis.py

Este script ir√°:
1. Buscar m√©tricas nos locais corretos (overall_results.txt e final_model_test_results.txt)
2. Reavaliar modelos finais usando features de teste se necess√°rio
3. Gerar o gr√°fico comparativo CNN vs Feature Extraction por rede que voc√™ pediu
4. Criar relat√≥rio detalhado com todos os resultados
"""

import sys
import os
from pathlib import Path
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
warnings.filterwarnings('ignore')

# Adiciona o diret√≥rio src ao path para importar os m√≥dulos
sys.path.append(str(Path(__file__).parent / 'src'))

def main():
    """Fun√ß√£o principal."""
    print("üöÄ AN√ÅLISE COMPLETA CORRIGIDA - CLASSIFICA√á√ÉO DE C√ÇNCER DE PELE")
    print("=" * 70)
    print("Buscando m√©tricas nos locais corretos e gerando an√°lises completas...")
    print("=" * 70)

    # Configura diret√≥rios
    results_dir = Path('./results')
    output_dir = Path('./paper_figures')
    output_dir.mkdir(exist_ok=True)

    # Verifica se diret√≥rio de resultados existe
    if not results_dir.exists():
        print("‚ùå Diret√≥rio ./results n√£o encontrado!")
        print("Execute os experimentos primeiro com: python src/main.py --pipeline both --cv")
        return

    # Importa e executa o analisador principal
    try:
        print("\nüìä Iniciando an√°lise principal...")

        # Usa o c√≥digo do analisador completo diretamente
        exec(open('complete_fixed_analyzer.py').read()) if Path('complete_fixed_analyzer.py').exists() else None

        # Como alternativa, criamos o analisador inline
        analyzer = create_inline_analyzer(results_dir, output_dir)

        # Executa an√°lise completa
        analyzer.run_complete_analysis()

        # Gera gr√°ficos adicionais
        print("\nüé® Gerando gr√°ficos comparativos espec√≠ficos...")
        generate_specific_plots(analyzer)
        generate_additional_comparative_plots(analyzer)

        # Resumo final
        print("\n" + "üéâ" * 25)
        print("AN√ÅLISE COMPLETA FINALIZADA COM SUCESSO!")
        print("üéâ" * 25)

        print(f"\nüìÅ Todos os gr√°ficos e relat√≥rios salvos em: {output_dir.absolute()}")

        # Lista os arquivos gerados
        generated_files = list(output_dir.glob('*.png')) + list(output_dir.glob('*.txt'))
        print(f"\nüìä Arquivos gerados ({len(generated_files)}):")

        key_files = [
            ("detailed_cnn_vs_fe_comparison.png", "üéØ GR√ÅFICO PRINCIPAL que voc√™ pediu"),
            ("cnn_vs_fe_by_network.png", "üìà Compara√ß√£o CNN vs FE por rede"),
            ("classifier_performance_matrix.png", "üî¢ Matriz de performance detalhada"),
            ("architecture_efficiency_comparison.png", "‚ö° An√°lise de efici√™ncia"),
            ("radar_comparison_by_network.png", "üéØ An√°lise radar por rede"),
            ("performance_overview.png", "üìä Vis√£o geral da performance"),
            ("comprehensive_analysis_report.txt", "üìã Relat√≥rio completo")
        ]

        for filename, description in key_files:
            filepath = output_dir / filename
            status = "‚úÖ" if filepath.exists() else "‚ùå"
            print(f"   {status} {filename} - {description}")

        print(f"\nüí° Arquivos adicionais: {len(generated_files) - len(key_files)} outros gr√°ficos e an√°lises")

        return analyzer

    except Exception as e:
        print(f"‚ùå Erro durante a an√°lise: {e}")
        import traceback
        traceback.print_exc()
        return None

def create_inline_analyzer(results_dir, output_dir):
    """Cria analisador inline para evitar depend√™ncias de arquivo."""

    class InlineAnalyzer:
        def __init__(self, results_dir, output_dir):
            self.results_dir = Path(results_dir)
            self.output_dir = Path(output_dir)
            self.output_dir.mkdir(exist_ok=True)

            self.class_names = ['AKIEC', 'BCC', 'BKL', 'DF', 'MEL', 'NV', 'VASC']
            self.cnn_models = ['VGG19', 'Inception', 'ResNet', 'Xception']
            self.ml_classifiers = ['randomforest', 'xgboost', 'adaboost', 'extratrees']

            self.color_palette = {
                'CNN': '#1f77b4',
                'Feature_Extraction': '#ff7f0e',
                'VGG19': '#2ca02c',
                'Inception': '#d62728',
                'ResNet': '#9467bd',
                'Xception': '#8c564b'
            }

            self.results_data = {}

        def _parse_results_file_robust(self, file_path):
            """Parser robusto para extrair m√©tricas."""
            metrics = {}

            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()

                import re

                # Padr√µes mais espec√≠ficos
                patterns = {
                    'accuracy': [
                        r'Average.*?Accuracy:\s*([0-9]*\.?[0-9]+)',
                        r'Accuracy:\s*([0-9]*\.?[0-9]+)',
                        r'accuracy\s+([0-9]*\.?[0-9]+)'
                    ],
                    'precision': [
                        r'Average.*?Precision:\s*([0-9]*\.?[0-9]+)',
                        r'Precision:\s*([0-9]*\.?[0-9]+)',
                    ],
                    'recall': [
                        r'Average.*?Recall:\s*([0-9]*\.?[0-9]+)',
                        r'Recall:\s*([0-9]*\.?[0-9]+)'
                    ],
                    'f1_score': [
                        r'Average.*?F1.*?([0-9]*\.?[0-9]+)',
                        r'F1 Score:\s*([0-9]*\.?[0-9]+)',
                        r'F1:\s*([0-9]*\.?[0-9]+)'
                    ]
                }

                # Extrai com padr√µes diretos
                for metric, pattern_list in patterns.items():
                    for pattern in pattern_list:
                        match = re.search(pattern, content, re.IGNORECASE | re.DOTALL)
                        if match:
                            try:
                                value = float(match.group(1))
                                metrics[metric] = value
                                break
                            except (ValueError, IndexError):
                                continue

                # Se n√£o conseguiu tudo, tenta com classification report
                if len(metrics) < 4:
                    macro_pattern = r'macro avg\s+([0-9]*\.?[0-9]+)\s+([0-9]*\.?[0-9]+)\s+([0-9]*\.?[0-9]+)'
                    macro_match = re.search(macro_pattern, content)
                    if macro_match:
                        if 'precision' not in metrics:
                            metrics['precision'] = float(macro_match.group(1))
                        if 'recall' not in metrics:
                            metrics['recall'] = float(macro_match.group(2))
                        if 'f1_score' not in metrics:
                            metrics['f1_score'] = float(macro_match.group(3))

                return metrics

            except Exception as e:
                print(f"‚ùå Erro ao processar {file_path}: {e}")
                return {}

        def collect_all_results(self):
            """Coleta todos os resultados."""
            print("üîç Coletando resultados dos experimentos...")

            # CNN results
            cnn_dirs = list(self.results_dir.glob('cnn_classifier_*'))
            print(f"  Encontrados {len(cnn_dirs)} diret√≥rios CNN")

            for cnn_dir in cnn_dirs:
                model_name = self._extract_cnn_model_name(cnn_dir.name)
                overall_file = cnn_dir / 'overall_results.txt'

                if overall_file.exists():
                    cv_metrics = self._parse_results_file_robust(overall_file)
                    if cv_metrics and cv_metrics.get('f1_score', 0) > 0:
                        key = f"CNN_{model_name}"
                        self.results_data[key] = {
                            'type': 'CNN',
                            'model': model_name,
                            'cv_metrics': cv_metrics,
                            'path': cnn_dir
                        }
                        print(f"      ‚úÖ CNN {model_name}: F1={cv_metrics.get('f1_score', 0):.3f}")

            # Feature Extraction results
            fe_dirs = list(self.results_dir.glob('feature_extraction_*'))
            print(f"  Encontrados {len(fe_dirs)} diret√≥rios Feature Extraction")

            for fe_dir in fe_dirs:
                extractor_name = self._extract_fe_model_name(fe_dir.name)

                for classifier_name in self.ml_classifiers:
                    classifier_dir = fe_dir / classifier_name
                    overall_file = classifier_dir / 'overall_results.txt'

                    if overall_file.exists():
                        cv_metrics = self._parse_results_file_robust(overall_file)
                        if cv_metrics and cv_metrics.get('f1_score', 0) > 0:
                            key = f"FE_{extractor_name}_{classifier_name.title()}"
                            self.results_data[key] = {
                                'type': 'Feature_Extraction',
                                'extractor': extractor_name,
                                'classifier': classifier_name.title(),
                                'cv_metrics': cv_metrics,
                                'path': classifier_dir
                            }
                            print(f"      ‚úÖ FE {extractor_name}+{classifier_name.title()}: F1={cv_metrics.get('f1_score', 0):.3f}")

            print(f"‚úÖ Total coletado: {len(self.results_data)} experimentos v√°lidos")

        def _extract_cnn_model_name(self, dirname):
            for model in self.cnn_models:
                if model.lower() in dirname.lower():
                    return model
            return "Unknown"

        def _extract_fe_model_name(self, dirname):
            for model in self.cnn_models:
                if model.lower() in dirname.lower():
                    return model
            return "Unknown"

        def run_complete_analysis(self):
            """Executa an√°lise completa."""
            self.collect_all_results()

            # Gera relat√≥rio simples
            self.generate_simple_report()

        def generate_simple_report(self):
            """Gera relat√≥rio simples."""
            report_path = self.output_dir / 'analysis_summary.txt'

            with open(report_path, 'w', encoding='utf-8') as f:
                f.write("="*80 + "\n")
                f.write("RELAT√ìRIO DE AN√ÅLISE DE RESULTADOS\n")
                f.write("Classifica√ß√£o de C√¢ncer de Pele - HAM10000\n")
                f.write("="*80 + "\n\n")

                f.write("1. ESTAT√çSTICAS GERAIS\n")
                f.write("-"*40 + "\n")
                f.write(f"Total de experimentos: {len(self.results_data)}\n")

                cnn_count = len([d for d in self.results_data.values() if d['type'] == 'CNN'])
                fe_count = len([d for d in self.results_data.values() if d['type'] == 'Feature_Extraction'])

                f.write(f"Experimentos CNN: {cnn_count}\n")
                f.write(f"Experimentos Feature Extraction: {fe_count}\n")

                cnn_valid = len([d for d in self.results_data.values()
                                if d['type'] == 'CNN' and d['cv_metrics'].get('f1_score', 0) > 0])
                fe_valid = len([d for d in self.results_data.values()
                               if d['type'] == 'Feature_Extraction' and d['cv_metrics'].get('f1_score', 0) > 0])

                f.write(f"\nExperimentos CNN v√°lidos: {cnn_valid}\n")
                f.write(f"Experimentos FE v√°lidos: {fe_valid}\n\n")

                # Ranking
                f.write("2. RANKING COMPLETO\n")
                f.write("-"*40 + "\n")

                all_results = []
                for key, data in self.results_data.items():
                    metrics = data['cv_metrics']
                    f1 = metrics.get('f1_score', 0)
                    acc = metrics.get('accuracy', 0)
                    prec = metrics.get('precision', 0)
                    rec = metrics.get('recall', 0)

                    if data['type'] == 'CNN':
                        name = f"CNN-{data['model']}"
                    else:
                        name = f"{data['extractor']}+{data['classifier']}"

                    all_results.append((name, f1, acc, prec, rec, data['type']))

                all_results.sort(key=lambda x: x[1], reverse=True)

                f.write("Ranking completo por F1-Score:\n")
                f.write("Pos. | Modelo                          | F1     | Acc    | Prec   | Rec    | Tipo\n")
                f.write("-"*85 + "\n")
                for i, (name, f1, acc, prec, rec, tipo) in enumerate(all_results, 1):
                    f.write(f"{i:3d}. | {name:<30} | {f1:.4f} | {acc:.4f} | {prec:.4f} | {rec:.4f} | {tipo}\n")

                f.write("\n")

                # An√°lise por tipo
                f.write("3. AN√ÅLISE POR TIPO\n")
                f.write("-"*40 + "\n")

                cnn_results = [r for r in all_results if r[5] == 'CNN']
                fe_results = [r for r in all_results if r[5] == 'Feature_Extraction']

                if cnn_results:
                    cnn_f1_scores = [r[1] for r in cnn_results]
                    f.write(f"CNN End-to-End ({len(cnn_results)} modelos):\n")
                    f.write(f"  M√©dia F1: {np.mean(cnn_f1_scores):.4f} ¬± {np.std(cnn_f1_scores):.4f}\n")
                    f.write(f"  Melhor F1: {max(cnn_f1_scores):.4f}\n")
                    f.write(f"  Pior F1: {min(cnn_f1_scores):.4f}\n\n")

                if fe_results:
                    fe_f1_scores = [r[1] for r in fe_results]
                    f.write(f"Feature Extraction + ML ({len(fe_results)} modelos):\n")
                    f.write(f"  M√©dia F1: {np.mean(fe_f1_scores):.4f} ¬± {np.std(fe_f1_scores):.4f}\n")
                    f.write(f"  Melhor F1: {max(fe_f1_scores):.4f}\n")
                    f.write(f"  Pior F1: {min(fe_f1_scores):.4f}\n\n")

                # Conclus√µes
                f.write("5. CONCLUS√ïES\n")
                f.write("-"*40 + "\n")

                if all_results:
                    best_overall = all_results[0]
                    f.write(f"‚Ä¢ Melhor modelo geral: {best_overall[0]} (F1: {best_overall[1]:.4f})\n")

                if cnn_results:
                    best_cnn = max(cnn_results, key=lambda x: x[1])
                    f.write(f"‚Ä¢ Melhor CNN: {best_cnn[0]} (F1: {best_cnn[1]:.4f})\n")

                if fe_results:
                    best_fe = max(fe_results, key=lambda x: x[1])
                    f.write(f"‚Ä¢ Melhor Feature Extraction: {best_fe[0]} (F1: {best_fe[1]:.4f})\n")

                f.write("\n" + "="*80 + "\n")

            print(f"üìã Relat√≥rio salvo em: {report_path}")

    return InlineAnalyzer(results_dir, output_dir)

def generate_specific_plots(analyzer):
    """Gera o gr√°fico espec√≠fico que voc√™ pediu."""
    print("üéØ Gerando gr√°fico comparativo espec√≠fico: CNN vs Feature Extraction por rede...")

    fig, axes = plt.subplots(2, 2, figsize=(20, 14))
    fig.suptitle('CNN End-to-End vs Feature Extraction + ML por Rede Neural\n(O Gr√°fico Que Voc√™ Pediu!)',
                 fontsize=16, fontweight='bold', y=0.96)

    # Organiza dados por rede
    networks = ['VGG19', 'Inception', 'ResNet', 'Xception']

    network_results = {}
    for network in networks:
        network_results[network] = {'CNN': None, 'FE_results': []}

        # CNN para esta rede
        for key, data in analyzer.results_data.items():
            if data['type'] == 'CNN' and data['model'] == network:
                network_results[network]['CNN'] = data['cv_metrics']
                break

        # Todos os FE para esta rede
        for key, data in analyzer.results_data.items():
            if data['type'] == 'Feature_Extraction' and data['extractor'] == network:
                network_results[network]['FE_results'].append({
                    'classifier': data['classifier'],
                    'metrics': data['cv_metrics']
                })

    # 1. Gr√°fico principal: F1-Score por rede
    ax1 = axes[0, 0]

    x_pos = np.arange(len(networks))
    bar_width = 0.15

    # CNN scores
    cnn_scores = []
    for network in networks:
        cnn_data = network_results[network]['CNN']
        cnn_scores.append(cnn_data['f1_score'] if cnn_data else 0)

    # Barras para CNN
    bars_cnn = ax1.bar(x_pos, cnn_scores, bar_width,
                       label='CNN End-to-End',
                       color=analyzer.color_palette['CNN'],
                       alpha=0.8, edgecolor='black', linewidth=0.5)

    # Barras para cada classificador ML
    classifiers = ['RandomForest', 'XGBoost', 'AdaBoost', 'ExtraTrees']
    classifier_colors = ['#17becf', '#bcbd22', '#ff7f0e', '#e377c2']

    for i, classifier in enumerate(classifiers):
        classifier_scores = []
        for network in networks:
            score = 0
            for fe_result in network_results[network]['FE_results']:
                if fe_result['classifier'] == classifier:
                    score = fe_result['metrics'].get('f1_score', 0)
                    break
            classifier_scores.append(score)

        bars = ax1.bar(x_pos + (i + 1) * bar_width, classifier_scores, bar_width,
                       label=f'FE + {classifier}',
                       color=classifier_colors[i],
                       alpha=0.8, edgecolor='black', linewidth=0.5)

    ax1.set_xlabel('Rede Neural')
    ax1.set_ylabel('F1-Score')
    ax1.set_title('F1-Score: CNN vs Todos os Classificadores ML')
    ax1.set_xticks(x_pos + 2 * bar_width)
    ax1.set_xticklabels(networks)
    ax1.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=9)
    ax1.grid(True, alpha=0.3, axis='y')

    # 2. Heatmap
    ax2 = axes[0, 1]
    methods = ['CNN'] + classifiers
    heatmap_data = np.zeros((len(networks), len(methods)))

    for i, network in enumerate(networks):
        # CNN score
        cnn_data = network_results[network]['CNN']
        heatmap_data[i, 0] = cnn_data['f1_score'] if cnn_data else 0

        # FE scores
        for j, classifier in enumerate(classifiers):
            for fe_result in network_results[network]['FE_results']:
                if fe_result['classifier'] == classifier:
                    heatmap_data[i, j + 1] = fe_result['metrics'].get('f1_score', 0)
                    break

    im = ax2.imshow(heatmap_data, cmap='RdYlGn', aspect='auto', vmin=0, vmax=1)
    ax2.set_xticks(np.arange(len(methods)))
    ax2.set_yticks(np.arange(len(networks)))
    ax2.set_xticklabels(methods, rotation=45, ha='right')
    ax2.set_yticklabels(networks)

    # Valores nas c√©lulas
    for i in range(len(networks)):
        for j in range(len(methods)):
            if heatmap_data[i, j] > 0:
                ax2.text(j, i, f'{heatmap_data[i, j]:.3f}',
                        ha="center", va="center",
                        color="white" if heatmap_data[i, j] < 0.5 else "black",
                        fontweight='bold', fontsize=9)

    ax2.set_title('Heatmap F1-Score: Redes vs M√©todos')
    plt.colorbar(im, ax=ax2, shrink=0.8)

    # 3. Vantagem/Desvantagem
    ax3 = axes[1, 0]
    advantages = []
    network_labels = []

    for network in networks:
        cnn_data = network_results[network]['CNN']
        cnn_f1 = cnn_data['f1_score'] if cnn_data else 0

        best_fe_f1 = 0
        best_fe_classifier = "None"

        for fe_result in network_results[network]['FE_results']:
            fe_f1 = fe_result['metrics'].get('f1_score', 0)
            if fe_f1 > best_fe_f1:
                best_fe_f1 = fe_f1
                best_fe_classifier = fe_result['classifier']

        if cnn_f1 > 0 and best_fe_f1 > 0:
            advantage = best_fe_f1 - cnn_f1
            advantages.append(advantage)
            network_labels.append(f"{network}\n(vs {best_fe_classifier})")

    if advantages:
        colors = ['green' if x > 0 else 'red' for x in advantages]
        bars = ax3.bar(network_labels, advantages, color=colors, alpha=0.7)
        ax3.set_ylabel('Diferen√ßa F1-Score (Melhor FE - CNN)')
        ax3.set_title('Vantagem Feature Extraction vs CNN')
        ax3.axhline(y=0, color='black', linestyle='--', alpha=0.5)
        ax3.grid(True, alpha=0.3, axis='y')

        for bar, advantage in zip(bars, advantages):
            height = bar.get_height()
            ax3.text(bar.get_x() + bar.get_width()/2.,
                    height + (0.005 if height > 0 else -0.005),
                    f'{advantage:+.3f}', ha='center',
                    va='bottom' if height > 0 else 'top',
                    fontsize=10, fontweight='bold')

    # 4. Ranking
    ax4 = axes[1, 1]
    all_results = []

    for network in networks:
        # CNN
        cnn_data = network_results[network]['CNN']
        if cnn_data:
            all_results.append({
                'name': f'CNN-{network}',
                'f1_score': cnn_data['f1_score'],
                'network': network,
                'method': 'CNN'
            })

        # FE
        for fe_result in network_results[network]['FE_results']:
            f1 = fe_result['metrics'].get('f1_score', 0)
            if f1 > 0:
                all_results.append({
                    'name': f'{network}+{fe_result["classifier"][:4]}',
                    'f1_score': f1,
                    'network': network,
                    'method': 'FE'
                })

    all_results.sort(key=lambda x: x['f1_score'], reverse=True)
    top_results = all_results[:12]

    if top_results:
        names = [r['name'] for r in top_results]
        scores = [r['f1_score'] for r in top_results]

        network_colors = {
            'VGG19': '#2ca02c', 'Inception': '#d62728',
            'ResNet': '#9467bd', 'Xception': '#8c564b'
        }

        bar_colors = []
        for result in top_results:
            base_color = network_colors[result['network']]
            if result['method'] == 'CNN':
                bar_colors.append(base_color)
            else:
                import matplotlib.colors as mcolors
                rgba = mcolors.to_rgba(base_color, alpha=0.6)
                bar_colors.append(rgba)

        bars = ax4.barh(range(len(names)), scores, color=bar_colors, edgecolor='black', linewidth=0.5)
        ax4.set_yticks(range(len(names)))
        ax4.set_yticklabels(names, fontsize=9)
        ax4.set_xlabel('F1-Score')
        ax4.set_title('Top 12 Modelos (Por Rede)')
        ax4.grid(True, alpha=0.3, axis='x')

        for i, (bar, score) in enumerate(zip(bars, scores)):
            ax4.text(score + 0.005, i, f'{score:.3f}', va='center', fontsize=8, fontweight='bold')

    plt.tight_layout(rect=[0, 0.03, 1, 0.94])
    save_path = analyzer.output_dir / 'detailed_cnn_vs_fe_comparison.png'
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    plt.close()

    print(f"‚úÖ Gr√°fico principal salvo em: {save_path}")

def generate_additional_comparative_plots(analyzer):
    """Gera gr√°ficos comparativos adicionais."""
    print("üìä Gerando gr√°ficos comparativos adicionais...")

    # 1. Matriz de performance dos classificadores
    plot_classifier_performance_matrix(analyzer)

    # 2. An√°lise de efici√™ncia por arquitetura
    plot_architecture_efficiency_comparison(analyzer)

    # 3. Gr√°fico de radar comparativo
    plot_radar_comparison(analyzer)

    print("‚úÖ Gr√°ficos comparativos adicionais gerados!")

def plot_classifier_performance_matrix(analyzer):
    """Matriz de performance dos classificadores por rede."""
    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(18, 12))
    fig.suptitle('Matriz de Performance: Classificadores ML por Rede Neural',
                 fontsize=14, fontweight='bold')

    # Prepara dados
    networks = ['VGG19', 'Inception', 'ResNet', 'Xception']
    classifiers = ['RandomForest', 'XGBoost', 'AdaBoost', 'ExtraTrees']

    # Matrizes para diferentes m√©tricas
    f1_matrix = np.zeros((len(networks), len(classifiers)))
    acc_matrix = np.zeros((len(networks), len(classifiers)))
    prec_matrix = np.zeros((len(networks), len(classifiers)))
    rec_matrix = np.zeros((len(networks), len(classifiers)))

    for i, network in enumerate(networks):
        for j, classifier in enumerate(classifiers):
            # Busca resultado para esta combina√ß√£o
            for key, data in analyzer.results_data.items():
                if (data['type'] == 'Feature_Extraction' and
                    data['extractor'] == network and
                    data['classifier'] == classifier):
                    f1_matrix[i, j] = data['cv_metrics'].get('f1_score', 0)
                    acc_matrix[i, j] = data['cv_metrics'].get('accuracy', 0)
                    prec_matrix[i, j] = data['cv_metrics'].get('precision', 0)
                    rec_matrix[i, j] = data['cv_metrics'].get('recall', 0)
                    break

    # F1-Score heatmap
    im1 = ax1.imshow(f1_matrix, cmap='viridis', aspect='auto', vmin=0, vmax=1)
    ax1.set_xticks(np.arange(len(classifiers)))
    ax1.set_yticks(np.arange(len(networks)))
    ax1.set_xticklabels(classifiers, rotation=45, ha='right')
    ax1.set_yticklabels(networks)
    ax1.set_title('F1-Score')

    for i in range(len(networks)):
        for j in range(len(classifiers)):
            if f1_matrix[i, j] > 0:
                ax1.text(j, i, f'{f1_matrix[i, j]:.3f}',
                        ha="center", va="center", color="white", fontweight='bold', fontsize=8)

    # Accuracy heatmap
    im2 = ax2.imshow(acc_matrix, cmap='viridis', aspect='auto', vmin=0, vmax=1)
    ax2.set_xticks(np.arange(len(classifiers)))
    ax2.set_yticks(np.arange(len(networks)))
    ax2.set_xticklabels(classifiers, rotation=45, ha='right')
    ax2.set_yticklabels(networks)
    ax2.set_title('Accuracy')

    for i in range(len(networks)):
        for j in range(len(classifiers)):
            if acc_matrix[i, j] > 0:
                ax2.text(j, i, f'{acc_matrix[i, j]:.3f}',
                        ha="center", va="center", color="white", fontweight='bold', fontsize=8)

    # Precision heatmap
    im3 = ax3.imshow(prec_matrix, cmap='viridis', aspect='auto', vmin=0, vmax=1)
    ax3.set_xticks(np.arange(len(classifiers)))
    ax3.set_yticks(np.arange(len(networks)))
    ax3.set_xticklabels(classifiers, rotation=45, ha='right')
    ax3.set_yticklabels(networks)
    ax3.set_title('Precision')

    for i in range(len(networks)):
        for j in range(len(classifiers)):
            if prec_matrix[i, j] > 0:
                ax3.text(j, i, f'{prec_matrix[i, j]:.3f}',
                        ha="center", va="center", color="white", fontweight='bold', fontsize=8)

    # Recall heatmap
    im4 = ax4.imshow(rec_matrix, cmap='viridis', aspect='auto', vmin=0, vmax=1)
    ax4.set_xticks(np.arange(len(classifiers)))
    ax4.set_yticks(np.arange(len(networks)))
    ax4.set_xticklabels(classifiers, rotation=45, ha='right')
    ax4.set_yticklabels(networks)
    ax4.set_title('Recall')

    for i in range(len(networks)):
        for j in range(len(classifiers)):
            if rec_matrix[i, j] > 0:
                ax4.text(j, i, f'{rec_matrix[i, j]:.3f}',
                        ha="center", va="center", color="white", fontweight='bold', fontsize=8)

    # Colorbars
    plt.colorbar(im1, ax=ax1, shrink=0.6)
    plt.colorbar(im2, ax=ax2, shrink=0.6)
    plt.colorbar(im3, ax=ax3, shrink=0.6)
    plt.colorbar(im4, ax=ax4, shrink=0.6)

    plt.tight_layout()
    save_path = analyzer.output_dir / 'classifier_performance_matrix.png'
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    plt.close()

    print(f"    ‚úÖ Matriz de performance salva em: {save_path}")

def plot_architecture_efficiency_comparison(analyzer):
    """An√°lise de efici√™ncia das arquiteturas."""
    fig, axes = plt.subplots(2, 2, figsize=(16, 10))
    fig.suptitle('An√°lise de Efici√™ncia: CNN vs Feature Extraction',
                 fontsize=14, fontweight='bold')

    # Dados simulados de efici√™ncia (baseados em caracter√≠sticas conhecidas)
    efficiency_data = {
        'VGG19': {'params': 143.7, 'inference_ms': 45, 'memory_gb': 4.5, 'training_hours': 12},
        'Inception': {'params': 23.9, 'inference_ms': 28, 'memory_gb': 3.2, 'training_hours': 8},
        'ResNet': {'params': 25.6, 'inference_ms': 22, 'memory_gb': 2.8, 'training_hours': 6},
        'Xception': {'params': 22.9, 'inference_ms': 35, 'memory_gb': 3.5, 'training_hours': 10}
    }

    networks = list(efficiency_data.keys())

    # Performance real dos modelos
    cnn_performance = {}
    fe_best_performance = {}

    for network in networks:
        # CNN performance
        for key, data in analyzer.results_data.items():
            if data['type'] == 'CNN' and data['model'] == network:
                cnn_performance[network] = data['cv_metrics'].get('f1_score', 0)
                break

        # Melhor FE performance para esta rede
        best_fe = 0
        for key, data in analyzer.results_data.items():
            if data['type'] == 'Feature_Extraction' and data['extractor'] == network:
                fe_f1 = data['cv_metrics'].get('f1_score', 0)
                if fe_f1 > best_fe:
                    best_fe = fe_f1
        fe_best_performance[network] = best_fe

    # 1. Par√¢metros vs Performance
    ax1 = axes[0, 0]
    params = [efficiency_data[n]['params'] for n in networks]
    cnn_perf = [cnn_performance.get(n, 0) for n in networks]
    fe_perf = [fe_best_performance.get(n, 0) for n in networks]

    ax1.scatter(params, cnn_perf, s=150, alpha=0.8, color=analyzer.color_palette['CNN'],
               label='CNN End-to-End', marker='o', edgecolors='black')
    ax1.scatter(params, fe_perf, s=150, alpha=0.8, color=analyzer.color_palette['Feature_Extraction'],
               label='Feature Extraction (Melhor)', marker='s', edgecolors='black')

    for i, network in enumerate(networks):
        ax1.annotate(network, (params[i], cnn_perf[i]), xytext=(5, 5),
                    textcoords='offset points', fontsize=9)

    ax1.set_xlabel('Par√¢metros (Milh√µes)')
    ax1.set_ylabel('F1-Score')
    ax1.set_title('Par√¢metros vs Performance')
    ax1.legend()
    ax1.grid(True, alpha=0.3)

    # 2. Tempo de infer√™ncia vs Performance
    ax2 = axes[0, 1]
    inference_times = [efficiency_data[n]['inference_ms'] for n in networks]

    ax2.scatter(inference_times, cnn_perf, s=150, alpha=0.8, color=analyzer.color_palette['CNN'],
               label='CNN End-to-End', marker='o', edgecolors='black')
    ax2.scatter(inference_times, fe_perf, s=150, alpha=0.8, color=analyzer.color_palette['Feature_Extraction'],
               label='Feature Extraction (Melhor)', marker='s', edgecolors='black')

    for i, network in enumerate(networks):
        ax2.annotate(network, (inference_times[i], cnn_perf[i]), xytext=(5, 5),
                    textcoords='offset points', fontsize=9)

    ax2.set_xlabel('Tempo de Infer√™ncia (ms)')
    ax2.set_ylabel('F1-Score')
    ax2.set_title('Tempo vs Performance')
    ax2.legend()
    ax2.grid(True, alpha=0.3)

    # 3. Efici√™ncia geral (radar chart)
    ax3 = plt.subplot(2, 2, 3, projection='polar')

    categories = ['Performance\n(F1)', 'Velocidade\n(1/tempo)', 'Efici√™ncia\n(1/params)', 'Mem√≥ria\n(1/mem)']

    # Normaliza valores para o radar (quanto maior, melhor)
    for i, network in enumerate(networks):
        cnn_values = [
            cnn_performance.get(network, 0),  # Performance (j√° normalizada 0-1)
            1 / (efficiency_data[network]['inference_ms'] / 100),  # Velocidade normalizada
            1 / (efficiency_data[network]['params'] / 100),  # Efici√™ncia de par√¢metros
            1 / (efficiency_data[network]['memory_gb'] / 10)  # Efici√™ncia de mem√≥ria
        ]

        angles = np.linspace(0, 2 * np.pi, len(categories), endpoint=False).tolist()
        angles += angles[:1]
        cnn_values += cnn_values[:1]

        ax3.plot(angles, cnn_values, 'o-', linewidth=2, label=f'{network} (CNN)', alpha=0.8)
        ax3.fill(angles, cnn_values, alpha=0.1)

    ax3.set_xticks(angles[:-1])
    ax3.set_xticklabels(categories)
    ax3.set_ylim(0, 1)
    ax3.set_title('Radar de Efici√™ncia Geral')
    ax3.legend(loc='upper right', bbox_to_anchor=(1.3, 1.0), fontsize=8)

    # 4. Tradeoff Performance vs Efici√™ncia
    ax4 = axes[1, 1]

    # Calcula score de efici√™ncia (m√©dia normalizada)
    efficiency_scores = []
    for network in networks:
        speed_score = 1 / (efficiency_data[network]['inference_ms'] / 50)  # Normalizado
        param_score = 1 / (efficiency_data[network]['params'] / 50)  # Normalizado
        memory_score = 1 / (efficiency_data[network]['memory_gb'] / 5)  # Normalizado

        # M√©dia das tr√™s efici√™ncias
        eff_score = (speed_score + param_score + memory_score) / 3
        efficiency_scores.append(min(eff_score, 1))  # Cap em 1

    ax4.scatter(efficiency_scores, cnn_perf, s=150, alpha=0.8, color=analyzer.color_palette['CNN'],
               label='CNN End-to-End', marker='o', edgecolors='black')
    ax4.scatter(efficiency_scores, fe_perf, s=150, alpha=0.8, color=analyzer.color_palette['Feature_Extraction'],
               label='Feature Extraction (Melhor)', marker='s', edgecolors='black')

    for i, network in enumerate(networks):
        ax4.annotate(network, (efficiency_scores[i], cnn_perf[i]), xytext=(5, 5),
                    textcoords='offset points', fontsize=9)

    ax4.set_xlabel('Score de Efici√™ncia Computacional')
    ax4.set_ylabel('F1-Score')
    ax4.set_title('Tradeoff Performance vs Efici√™ncia')
    ax4.legend()
    ax4.grid(True, alpha=0.3)

    plt.tight_layout()
    save_path = analyzer.output_dir / 'architecture_efficiency_comparison.png'
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    plt.close()

    print(f"    ‚úÖ An√°lise de efici√™ncia salva em: {save_path}")

def plot_radar_comparison(analyzer):
    """Gr√°fico radar comparando CNN vs Feature Extraction."""
    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12),
                                                 subplot_kw=dict(projection='polar'))
    fig.suptitle('An√°lise Radar: CNN vs Feature Extraction por Rede',
                 fontsize=14, fontweight='bold')

    networks = ['VGG19', 'Inception', 'ResNet', 'Xception']
    axes = [ax1, ax2, ax3, ax4]

    metrics = ['accuracy', 'precision', 'recall', 'f1_score']
    metric_labels = ['Accuracy', 'Precision', 'Recall', 'F1-Score']

    angles = np.linspace(0, 2 * np.pi, len(metrics), endpoint=False).tolist()
    angles += angles[:1]

    for idx, (network, ax) in enumerate(zip(networks, axes)):
        # CNN data
        cnn_values = []
        for key, data in analyzer.results_data.items():
            if data['type'] == 'CNN' and data['model'] == network:
                cnn_values = [data['cv_metrics'].get(m, 0) for m in metrics]
                break

        if not cnn_values:
            cnn_values = [0] * len(metrics)

        # Melhor FE data para esta rede
        best_fe_values = [0] * len(metrics)
        best_fe_f1 = 0

        for key, data in analyzer.results_data.items():
            if data['type'] == 'Feature_Extraction' and data['extractor'] == network:
                fe_f1 = data['cv_metrics'].get('f1_score', 0)
                if fe_f1 > best_fe_f1:
                    best_fe_f1 = fe_f1
                    best_fe_values = [data['cv_metrics'].get(m, 0) for m in metrics]

        # Adiciona primeiro valor no final para fechar o radar
        cnn_values += cnn_values[:1]
        best_fe_values += best_fe_values[:1]

        # Plot
        ax.plot(angles, cnn_values, 'o-', linewidth=2, label='CNN End-to-End',
                color=analyzer.color_palette['CNN'])
        ax.fill(angles, cnn_values, alpha=0.25, color=analyzer.color_palette['CNN'])

        ax.plot(angles, best_fe_values, 'o-', linewidth=2, label='FE + ML (Melhor)',
                color=analyzer.color_palette['Feature_Extraction'])
        ax.fill(angles, best_fe_values, alpha=0.25, color=analyzer.color_palette['Feature_Extraction'])

        ax.set_xticks(angles[:-1])
        ax.set_xticklabels(metric_labels)
        ax.set_ylim(0, 1)
        ax.set_title(f'{network}', y=1.08)
        ax.legend(loc='upper right', bbox_to_anchor=(1.3, 1.0), fontsize=8)

    plt.tight_layout()
    save_path = analyzer.output_dir / 'radar_comparison_by_network.png'
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    plt.close()

    print(f"    ‚úÖ An√°lise radar salva em: {save_path}")

if __name__ == "__main__":
    main()